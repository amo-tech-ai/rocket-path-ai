# Prompt 03.1 — Smart AI System (Auto-Claude Adaptation)

> **Phase:** Foundation | **Priority:** P1 | **Overall:** 30%
> **No code — agent architecture, task lifecycle, spec pipeline, QA loops, and memory system only**
> **Source:** `tasks/dashboards/autoclaude/` (5 reference documents)

---

## Purpose

Smart AI is StartupAI's autonomous development and intelligence layer. Adapted from the Auto-Claude multi-agent framework, it adds AI task orchestration, spec-driven development, automated QA validation, cross-session memory, and real-time agent progress streaming on top of the existing 14-module product.

**Core Thesis:** Extract Auto-Claude's patterns (multi-agent orchestration, spec-driven development, QA validation loops, cross-session memory) and apply them through our existing Claude Code + Supabase Edge Functions + Skills stack.

---

## Smart AI Screens (10 Screens)

| # | Screen | Purpose | Agent | Priority |
|---|--------|---------|-------|----------|
| 1 | AI Task Kanban | Task lifecycle dashboard (Planning → Queue → In Progress → AI Review → Human Review → Done) | Orchestrator | P0 |
| 2 | Spec Creator | Natural language → structured implementation spec with acceptance criteria | Planner + Spec Writer | P0 |
| 3 | Agent Terminal | Live view of AI agent implementing a feature with streaming output | Coder | P1 |
| 4 | QA Dashboard | Pass/fail per acceptance criterion with fix loop tracking | QA Reviewer + Fixer | P1 |
| 5 | AI Insights | Chat interface for codebase questions (security, performance, architecture) | Analyst | P1 |
| 6 | Roadmap Planner | Feature prioritization with dependency mapping and AI build order | Planner | P2 |
| 7 | Pattern Library | Browse cross-session patterns, gotchas, conventions | Memory Manager | P2 |
| 8 | Changelog | Auto-generated release notes from completed tasks | Content Writer | P2 |
| 9 | Cost Tracker | Per-agent, per-task, per-session token and dollar tracking | — | P3 |
| 10 | Smart AI Settings | Agent configuration: parallel limits, model preferences, approval gates | — | P3 |

---

## Agent Roles

| Agent | Model | Purpose | Permission Boundaries |
|-------|-------|---------|----------------------|
| Orchestrator | — | Coordinate multi-step workflows, assign agents, handle failures | Status updates only, no code, no deploy, $5/task |
| Planner | Sonnet 4.5 | Break features into subtasks, estimate complexity | Spec files only, $10/task |
| Coder | Sonnet 4.5 | Implement features in isolated worktrees | Write code in worktree, draft PR only, $50/task |
| QA Reviewer | Opus 4.5 | Validate acceptance criteria, generate reports | Read-only + QA results, $20/task |
| QA Fixer | Opus 4.5 | Fix issues found by reviewer, retest | Write code in worktree, $30/task |
| Spec Writer | Sonnet 4.5 | Gather requirements, write structured specs | Spec files only, $10/task |
| Spec Gatherer | Sonnet 4.5 | Discovery phase — scope, affected files | Read-only, $5/task |
| Recovery Manager | Sonnet 4.5 | Detect stuck agents, reset state, retry with context | Write code in worktree, $20/task |

### Agent Rules

- No agent can push to `main` directly — all changes go through PR + human approval
- No agent can modify auth, RLS policies, or environment variables
- Cost limits are per-task; session is killed if exceeded
- Orchestrator cannot escalate its own permissions
- After 8 QA iterations, task escalates to human — no infinite loops

---

## Task Lifecycle

```
Planning → Queue → In Progress → AI Review → Human Review → Done
                        ↑              |
                        |              ↓ (fail)
                        └──── QA Fix Loop (max 8 iterations)
```

| State | Description | Who Acts |
|-------|-------------|----------|
| Planning | Spec approved, ready to build | Founder starts |
| Queue | Waiting — parallel limit reached | System auto-promotes |
| In Progress | Agent actively coding in worktree | Coder agent |
| AI Review | QA Reviewer validating acceptance criteria | QA Reviewer |
| Human Review | QA passed, awaiting founder approval | Founder |
| Done | Approved and merged | System |
| Error | Agent failed, recovery in progress | Recovery Manager |
| Escalated | Max QA iterations reached | Founder must intervene |

---

## Spec Pipeline

Every feature goes through a structured spec before implementation:

| Phase | Agent | Output | Duration |
|-------|-------|--------|----------|
| Discovery | Spec Gatherer | Feature scope, affected files | Fast |
| Requirements | Spec Gatherer | Structured requirements (JSON) | Fast |
| Context Analysis | Code Explorer | Existing code patterns, dependencies | Medium |
| Spec Writing | Spec Writer | Full spec with acceptance criteria | Medium |
| Plan Generation | Planner | Subtasks with dependencies and estimates | Medium |
| Validation | Spec Critic | Completeness check (all gates must pass) | Fast |

### Spec Validation Gates

| Gate | Minimum | Required |
|------|---------|----------|
| Acceptance criteria | >= 3 | Yes |
| Each criterion testable (starts with verb) | 100% | Yes |
| Subtasks defined | >= 2 | Yes |
| Complexity estimate | Present | Yes |
| Rationale section | Present | Yes |
| User story or description | >= 1 sentence | Yes |
| Duplicate check (title similarity > 80%) | Must be unique | Yes |

---

## QA Validation Loop

| Step | Agent | Action |
|------|-------|--------|
| 1 | QA Reviewer | Test each acceptance criterion |
| 2 | — | All pass → move to Human Review |
| 3 | QA Fixer | If any fail → apply fix |
| 4 | QA Reviewer | Retest failed criteria |
| 5 | — | Repeat up to 8 iterations |
| 6 | — | After 8 failures → escalate to human |

### QA States

| State | Visual | Meaning |
|-------|--------|---------|
| Passed | Green check | Criterion met |
| Failed | Red X | Criterion not met |
| Fixing | Yellow spinner | QA Fixer working |
| Escalated | Orange alert | Max iterations, human needed |

---

## Database Schema (Smart AI Tables)

| Table | Purpose | Key Columns |
|-------|---------|-------------|
| `ai_tasks` | Task lifecycle tracking | id, title, status (planning/queued/in_progress/ai_review/human_review/done/error/escalated), spec_id, agent_type, priority, created_by |
| `ai_specs` | Structured implementation specs | id, title, requirements (JSON), acceptance_criteria (JSON), subtasks (JSON), complexity, context (JSON) |
| `ai_sessions` | Agent session logs | id, task_id, agent_type, model, tokens_used, cost_usd, outcome, duration_ms |
| `ai_qa_results` | QA criterion results | id, task_id, criterion, status (passed/failed), iteration, fix_applied |
| `ai_patterns` | Cross-session memory | id, category, pattern, gotcha, source_session_id, times_used, confidence_score (0-1), last_validated_at, superseded_by (FK self) |
| `ai_changelogs` | Auto-generated release notes | id, version, content_md, tasks_included (JSON), generated_at |

All tables require RLS policies scoped to user/org.

---

## Realtime Channels (Smart AI Layer)

| Channel | Source | Events | Used By |
|---------|--------|--------|---------|
| `kanban:{userId}:events` | Orchestrator, DB triggers | task_status_changed, task_started, task_completed, task_failed | Kanban, left nav counters |
| `agent:{taskId}:events` | Coder/QA agents | log_line, subtask_completed, build_passed, build_failed, file_changed | Agent Terminal |
| `qa:{taskId}:events` | QA Reviewer + Fixer | criterion_passed, criterion_failed, fix_applied, qa_complete | QA Dashboard |
| `spec:{specId}:events` | Spec Writer + Planner | phase_completed, requirements_extracted, subtasks_generated, spec_ready | Spec Creator |
| `cost:{userId}:events` | All agents | tokens_used, cost_updated, session_cost_total | Cost meter |
| `patterns:{projectId}:events` | All agents | pattern_discovered, gotcha_found, pattern_applied | Pattern Library |
| `roadmap:{projectId}:events` | Orchestrator | dependency_resolved, task_unblocked, phase_completed | Roadmap Planner |
| `changelog:{projectId}:events` | Content Writer | entry_generated, release_ready | Changelog |
| `memory:{projectId}:events` | Memory Manager | memory_saved, memory_retrieved | All screens (subtle indicator) |

**Broadcast vs Postgres Changes:** Agent progress streaming uses Supabase Broadcast (ephemeral, no DB writes for log lines). Only final results (task status, QA results, patterns) get persisted via Postgres Changes.

---

## Realtime Hooks (Smart AI)

| Hook | Channel | Returns |
|------|---------|---------|
| `useKanbanRealtime(userId)` | `kanban:{userId}:events` | taskStatuses, counts, recentChanges |
| `useAgentRealtime(taskId)` | `agent:{taskId}:events` | logLines, currentSubtask, filesChanged, buildStatus |
| `useQARealtime(taskId)` | `qa:{taskId}:events` | criteriaResults, iteration, isFixing, isComplete |
| `useSpecRealtime(specId)` | `spec:{specId}:events` | currentPhase, requirements, subtasks, isReady |
| `useCostRealtime(userId)` | `cost:{userId}:events` | tokenCount, costDollars, sessionTotal |
| `usePatternsRealtime(projectId)` | `patterns:{projectId}:events` | newPatterns, newGotchas |
| `useRoadmapRealtime(projectId)` | `roadmap:{projectId}:events` | unblockedTasks, resolvedDeps |
| `useChangelogRealtime(projectId)` | `changelog:{projectId}:events` | newEntries, isGenerating |
| `useMemoryRealtime(projectId)` | `memory:{projectId}:events` | isSaving, isRetrieving, lastPattern |

---

## Integration with Existing Modules

### How Smart AI Layers on Top of Product

| Product Feature | Smart AI Enhancement |
|----------------|---------------------|
| Lean Canvas (5 actions) | Spec-driven canvas improvements; QA validates canvas generation |
| Pitch Deck (7 actions) | Agent builds deck features; QA validates slide generation |
| CRM (15 actions) | Agent wires AI enrichment to frontend; QA validates scoring |
| Investors (12 actions) | Agent builds discovery UI; QA validates fit algorithm |
| Documents (6 actions) | Agent builds upload + AI analysis; QA validates |
| Dashboard | Agent builds KPI widgets; QA validates data aggregation |
| All modules | Pattern Library accumulates conventions; Memory speeds up future work |

### Mapping to Existing Skills

| Auto-Claude Agent | StartupAI Skill Equivalent |
|-------------------|---------------------------|
| Orchestrator | `ai-chat` edge function routing |
| Planner | `superpowers:writing-plans` |
| Coder | Domain skills (`frontend-design`, `edge-functions`, `supabase`) |
| QA Reviewer | `superpowers:verification-before-completion` |
| QA Fixer | `superpowers:systematic-debugging` |
| Spec Gatherer | `superpowers:brainstorming` |
| Recovery Manager | Error context + retry |

---

## Implementation Phases

### Phase 1: Foundation (Use Now — No New Infrastructure)

| Pattern | How |
|---------|-----|
| Spec-first development | Write spec.md before implementation |
| QA self-validation | End sessions with build check + acceptance criteria verification |
| Skills as agents | Invoke relevant skills for every task type |
| Worktree isolation | Feature branches for multi-file changes |
| Session memory | Document patterns in `.claude/` reference docs |

### Phase 2: Database Layer (Build with Edge Functions)

| Deliverable | Table/Function |
|-------------|---------------|
| Task lifecycle tracking | `ai_tasks` table with Kanban states |
| Spec storage | `ai_specs` table with structured JSON |
| QA results tracking | `ai_qa_results` table |
| Agent session logging | `ai_sessions` table |
| Pattern memory | `ai_patterns` table |
| Kanban Realtime | DB triggers on `ai_tasks` → broadcast |

### Phase 3: Agent Integration (New Edge Functions)

| Deliverable | Function |
|-------------|----------|
| AI orchestrator | `ai-orchestrator` edge function |
| QA validation endpoint | `ai-qa-validate` edge function |
| Spec creation flow | UI + `ai-spec-create` edge function |
| Session memory retrieval | Pattern matching via `ai_patterns` |

### Phase 4: Autonomous Pipeline (Advanced)

| Deliverable | Function |
|-------------|----------|
| Parallel agent dispatch | Queue system for multiple Claude Code sessions |
| Auto PR creation | QA pass → GitHub PR with AI summary |
| Semantic memory | pgvector embeddings over accumulated patterns |
| Self-improving system | Agents learn from past session outcomes |

---

## Worktree Configuration

| Setting | Value |
|---------|-------|
| Max active worktrees | 5 |
| Max worktree age | 7 days |
| Auto-cleanup on task Done | Yes |
| Auto-cleanup on task Failed | After 24 hours |
| Orphan detection | Daily |

---

## Cost Management

| Agent | Per-Task Limit | Model |
|-------|---------------|-------|
| Orchestrator | $5 | — |
| Planner | $10 | Sonnet 4.5 |
| Coder | $50 | Sonnet 4.5 |
| QA Reviewer | $20 | Opus 4.5 |
| QA Fixer | $30 | Opus 4.5 |
| Spec Writer | $10 | Sonnet 4.5 |
| Recovery Manager | $20 | Sonnet 4.5 |

### Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Features per week | 2-3 | 8-10 |
| First-pass QA rate | ~60% | 90% |
| Pattern reuse rate | 0% | 80% |
| Session ramp-up time | 15 min | 2 min |
| Cost per feature | Unknown | $30-50 |

---

## 3-Panel Layout (Smart AI Screens)

All Smart AI screens follow the same 3-panel layout as product screens:

| Panel | Width | Content |
|-------|-------|---------|
| Left (256px) | Navigation: Kanban, Terminal, Insights, Roadmap, Patterns, Changelog, Settings. Bottom: task counters, progress bar, memory indicator |
| Main (flex) | Primary workspace: Kanban board, terminal output, spec editor, roadmap cards |
| Right (360px) | Intelligence: selected task detail, QA results, AI suggestions, cost meter, subtask tracker |

---

## Acceptance Criteria

- Task cards move between Kanban columns via agent actions + founder approval
- Specs pass all 7 validation gates before entering Planning
- QA loop runs up to 8 iterations before escalating to human
- Agent Terminal streams live output via Supabase Broadcast
- Pattern Library persists discoveries across sessions
- Cost meter shows real-time token usage and dollar amount
- Human approval gates at spec approval and task completion (non-negotiable)
- All Smart AI tables have RLS policies
- Realtime channels clean up on component unmount

---

## Reference Documents

| Document | Path | Content |
|----------|------|---------|
| Smart AI Strategy | `tasks/dashboards/autoclaude/01-auto-smartai.md` | Adaptation strategy, agent roles, risk assessment |
| Screen Wireframes | `tasks/dashboards/autoclaude/02-auto-startupai-wireframes.md` | 10-screen wireframes with ASCII layouts |
| Mermaid Diagrams | `tasks/dashboards/autoclaude/03-mermaid-diagrams.md` | 12 architecture and flow diagrams |
| AI Realtime Design | `tasks/dashboards/autoclaude/04-ai-realtime-auto-startupai.md` | 9 channels, 9 hooks, event flows |
| Design Prompts | `tasks/dashboards/autoclaude/05-design-prompts.md` | Figma/Lovable-ready screen prompts |
